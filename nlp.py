# -*- coding: utf-8 -*-
"""nlp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dip6PwHMyuPrADj0Tp_n8SkBUjQk586P
"""

!pip install -U spacy
!python -m spacy download en_core_web_sm

import spacy

nlp = spacy.load("en_core_web_sm")

text = "Bro let's test this. SpaCy should work without crying like NLTK."
doc = nlp(text)

print([sent.text for sent in doc.sents])

medical_qa = """
Q: What is diabetes?
A: Diabetes is a chronic condition that affects how your body turns food into energy.

Q: What are symptoms of typhoid?
A: Symptoms include prolonged fever, fatigue, headache, nausea, and abdominal pain.

Q: How to treat a headache?
A: Stay hydrated, rest in a quiet room, and consider over-the-counter painkillers like ibuprofen.

Q: How to boost immunity?
A: Eat nutritious foods, exercise regularly, get quality sleep, and reduce stress.

Q: What is hypertension?
A: Hypertension is high blood pressure â€” a condition where blood pressure against artery walls is too high.

Q: What are the symptoms of COVID-19?
A: Common symptoms include fever, dry cough, fatigue, and loss of taste or smell.
"""

with open("medical_qa.txt", "w") as f:
    f.write(medical_qa)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.metrics.pairwise import cosine_similarity
# from transformers import pipeline
# 
# # ==== Load Generator ====
# @st.cache_resource
# def load_generator():
#     return pipeline("text2text-generation", model="google/flan-t5-base")
# 
# generator = load_generator()
# 
# # ==== Load Knowledge Base ====
# qa_pairs = []
# with open("medical_qa.txt", "r") as file:
#     lines = file.read().strip().split('\n')
#     if len(lines) % 2 != 0:
#         lines = lines[:-1]
#     for i in range(0, len(lines), 2):
#         q = lines[i].replace("Q: ", "").strip()
#         a = lines[i+1].replace("A: ", "").strip()
#         qa_pairs.append((q, a))
# 
# questions = [q for q, a in qa_pairs]
# answers = [a for q, a in qa_pairs]
# 
# # ==== TF-IDF Setup ====
# vectorizer = TfidfVectorizer()
# question_vectors = vectorizer.fit_transform(questions)
# 
# def get_top_k_context(user_input, k=3):
#     input_vec = vectorizer.transform([user_input])
#     similarity = cosine_similarity(input_vec, question_vectors).flatten()
#     top_k_idx = similarity.argsort()[-k:][::-1]
#     return [(questions[i], answers[i]) for i in top_k_idx if similarity[i] > 0.2]
# 
# def generate_with_context(context_pairs, user_question):
#     context_text = "\n".join([f"Q: {q}\nA: {a}" for q, a in context_pairs])
#     prompt = f"Context:\n{context_text}\n\nQuestion: {user_question}\nAnswer:"
#     result = generator(prompt, max_length=150, do_sample=True, top_p=0.9)[0]['generated_text']
#     return result
# 
# # ==== Streamlit Chat UI ====
# st.set_page_config(page_title="Medical Chatbot", layout="centered")
# st.title("ðŸ§  Real-Time Medical Chatbot (NLP + RAG)")
# st.markdown("Ask health-related questions below:")
# 
# # Session chat history
# if "chat_history" not in st.session_state:
#     st.session_state.chat_history = []
# 
# # Input box
# user_input = st.text_input("ðŸ‘¨â€âš•ï¸ You:", "")
# 
# if st.button("Ask") and user_input.strip() != "":
#     try:
#         context_pairs = get_top_k_context(user_input)
#         if context_pairs:
#             bot_reply = generate_with_context(context_pairs, user_input)
#         else:
#             bot_reply = "âŒ Sorry, I couldn't find anything relevant. Try rephrasing."
# 
#         st.session_state.chat_history.append(("You", user_input))
#         st.session_state.chat_history.append(("Bot", bot_reply))
# 
#     except Exception as e:
#         st.error(f"âš ï¸ Error: {e}")
# 
#         # Save conversation
#         st.session_state.chat_history.append(("You", user_input))
#         st.session_state.chat_history.append(("Bot", bot_reply))
# 
# # Show chat history
# for sender, msg in st.session_state.chat_history[::-1]:
#     st.markdown(f"**{sender}:** {msg}")
#

from pyngrok import ngrok
!streamlit run app.py &>/content/logs.txt &
public_url = ngrok.connect(addr=8501, proto='http')
print(f"ðŸ”— Your Medical Chatbot is live here: {public_url}")